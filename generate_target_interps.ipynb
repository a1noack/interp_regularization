{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torchvision.utils import make_grid\n",
    "import ir_utils.interp_generators as igs\n",
    "import ir_utils.dataloaders as dataloaders\n",
    "from ir_utils.simple_models import SimpleCNN\n",
    "import ir_utils.wide_resnet as wide_resnet\n",
    "import ir_utils.utils as utils\n",
    "\n",
    "device = torch.device(0 if torch.cuda.is_available() else 'cpu')\n",
    "torch.cuda.set_device(device)\n",
    "if device != 'cpu':\n",
    "    torch.set_default_tensor_type('torch.cuda.FloatTensor')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the robust model to be used to generate the ground truth saliency maps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('CIFAR-10', False)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = 'CIFAR-10'\n",
    "simp = False # if True, use simple gradient, False => use SmoothGrad\n",
    "\n",
    "if dataset == 'CIFAR-10':\n",
    "#     model_name = 'model_pgd2_eps0.314_iters7_42.pt'\n",
    "#     dir_name = 'pgdL2_eps0.314_iters7_smooth_unproc'\n",
    "    \n",
    "    model_name = 'model_0.pt'\n",
    "    dir_name = 'std_train_smooth_unproc'\n",
    "    \n",
    "\n",
    "elif dataset == 'MNIST':\n",
    "    pass\n",
    "#     model_name = 'model_pgd2_eps2.5_iters40_0.pt'\n",
    "#     dir_name = 'pgdL2_eps2.5_iters40_simp_unproc'\n",
    "    \n",
    "#     model_name = 'model_42.pt'\n",
    "#     dir_name = 'std_train_simp_unproc'\n",
    "\n",
    "#     model_name = 'model_42.pt'\n",
    "#     dir_name = 'std_train_smooth_unproc'\n",
    "    \n",
    "#     model_name = 'model_pgd2_eps1.5_iters40_42.pt'\n",
    "#     dir_name = 'pgdL2_eps1.5_iters40_smooth_unproc'\n",
    "    \n",
    "#     model_name = 'model_pgdinf_eps.3_iters40_0.pt'\n",
    "#     dir_name = 'pgdinf_eps.3_iters40_simp_unproc'\n",
    "\n",
    "if not os.path.isdir(f'data/{dataset}/{dir_name}'):\n",
    "    os.mkdir(f'data/{dataset}/{dir_name}')\n",
    "    \n",
    "dataset, simp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "\n"
     ]
    }
   ],
   "source": [
    "if dataset == 'CIFAR-10':\n",
    "    train_loader, test_loader = dataloaders.cifar10(batch_size=1, augment=False)\n",
    "    net = wide_resnet.Wide_ResNet(depth=28, widen_factor=10, dropout_rate=.3, num_classes=10)\n",
    "    net.load_state_dict(torch.load(f'trained_models/CIFAR-10/WRN-28-10_st/{model_name}', map_location=device))\n",
    "elif dataset == 'MNIST':\n",
    "    train_loader, test_loader = dataloaders.mnist(batch_size=1)\n",
    "    net = SimpleCNN()\n",
    "    net.load_state_dict(torch.load(f'trained_models/MNIST/SimpleCNN_st/{model_name}', map_location=device))\n",
    "\n",
    "net.cuda()\n",
    "net.eval(); print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### For each sample in both the train and test sets, generate a ground truth saliency map and save in new datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0/50000\n",
      "1000/50000\n",
      "2000/50000\n",
      "3000/50000\n",
      "4000/50000\n",
      "saved training5000.pt\n",
      "5000/50000\n",
      "6000/50000\n",
      "7000/50000\n",
      "8000/50000\n",
      "9000/50000\n",
      "saved training10000.pt\n",
      "10000/50000\n",
      "11000/50000\n",
      "12000/50000\n",
      "13000/50000\n",
      "14000/50000\n",
      "saved training15000.pt\n",
      "15000/50000\n",
      "16000/50000\n",
      "17000/50000\n",
      "18000/50000\n",
      "19000/50000\n",
      "saved training20000.pt\n",
      "20000/50000\n",
      "21000/50000\n",
      "22000/50000\n",
      "23000/50000\n",
      "24000/50000\n",
      "saved training25000.pt\n",
      "25000/50000\n",
      "26000/50000\n",
      "27000/50000\n",
      "28000/50000\n",
      "29000/50000\n",
      "saved training30000.pt\n",
      "30000/50000\n",
      "31000/50000\n",
      "32000/50000\n",
      "33000/50000\n",
      "34000/50000\n",
      "saved training35000.pt\n",
      "35000/50000\n",
      "36000/50000\n",
      "37000/50000\n",
      "38000/50000\n",
      "39000/50000\n",
      "saved training40000.pt\n",
      "40000/50000\n",
      "41000/50000\n",
      "42000/50000\n",
      "43000/50000\n",
      "44000/50000\n",
      "saved training45000.pt\n",
      "45000/50000\n",
      "46000/50000\n",
      "47000/50000\n",
      "48000/50000\n",
      "49000/50000\n",
      "saved training50000.pt\n",
      "0/10000\n",
      "1000/10000\n",
      "2000/10000\n",
      "3000/10000\n",
      "4000/10000\n",
      "saved test5000.pt\n",
      "5000/10000\n",
      "6000/10000\n",
      "7000/10000\n",
      "8000/10000\n",
      "9000/10000\n",
      "saved test10000.pt\n"
     ]
    }
   ],
   "source": [
    "for loader_name in ['training','test']:\n",
    "    i = 0\n",
    "    init = True\n",
    "    if loader_name == 'training':\n",
    "        loader = train_loader\n",
    "    else:\n",
    "        loader = test_loader\n",
    "        \n",
    "    samples = []\n",
    "    labels = []\n",
    "    salience_maps = []\n",
    "    \n",
    "    for sample, label in loader:\n",
    "#         print(sample.min(), sample.max())\n",
    "        if i % 1000 == 0:\n",
    "            print(f'{i}/{len(loader.dataset)}')\n",
    "            \n",
    "        # for sample,label in loader\n",
    "        sample, label = sample.to(device), label.to(device)\n",
    "        \n",
    "        if simp:\n",
    "            salience_map = igs.simple_gradient(net, sample, label, \n",
    "                                               normalize=False, rgb=dataset=='CIFAR-10', abs=False)\n",
    "            assert len(sample.size()) == 4\n",
    "            assert len(label.size()) == 1\n",
    "#             sample.requires_grad = True\n",
    "#             logits = net(sample)\n",
    "#             grad_outputs = F.one_hot(label, num_classes=10).float()\n",
    "#             salience_map = torch.autograd.grad(logits, sample, grad_outputs=grad_outputs, create_graph=False)[0]\n",
    "            assert len(salience_map.size()) == 4\n",
    "        else:\n",
    "            # SmoothGrad paper recommends 10-20% noise should be added. I.e. scale ~ .15\n",
    "            salience_map = igs.smoothgrad(net, sample, label, j=50, scale=.15, \n",
    "                                          normalize=False, rgb=dataset=='CIFAR-10', abs=False) \n",
    "            salience_map = salience_map.unsqueeze(0)\n",
    "            assert len(salience_map.size()) == 4\n",
    "            \n",
    "#         salience_map = utils.zero_one_scale(salience_map)\n",
    "#         img_list = []\n",
    "#         img_list.append(sample.squeeze(0).detach().cpu())\n",
    "#         img_list.append(salience_map.squeeze(0).cpu())\n",
    "\n",
    "#         utils.show(make_grid(img_list, nrow=4), size=8)\n",
    "                \n",
    "        samples.append(sample.detach().cpu())\n",
    "        labels.append(label.cpu())\n",
    "        salience_maps.append(salience_map.detach().cpu())\n",
    "\n",
    "        i+=1\n",
    "        \n",
    "        if i % 5000 == 0 and dataset == 'CIFAR-10':\n",
    "            samples, labels, salience_maps = torch.cat(samples, dim=0), torch.cat(labels, dim=0), torch.cat(salience_maps, dim=0)\n",
    "            torch.save((samples, labels, salience_maps), \n",
    "                       f'data/CIFAR-10/{dir_name}/{loader_name}{i}.pt')\n",
    "            print(f'saved {loader_name}{i}.pt')\n",
    "            samples, labels, salience_maps = [], [], []\n",
    "    \n",
    "    if dataset == 'MNIST':\n",
    "        samples, labels, salience_maps = torch.cat(samples, dim=0), torch.cat(labels, dim=0), torch.cat(salience_maps, dim=0)\n",
    "\n",
    "        try:\n",
    "            torch.save((samples, labels, salience_maps), f'data/MNIST/{dir_name}/{loader_name}.pt')\n",
    "            print(f'saved {loader_name}.pt')\n",
    "        except OSError:\n",
    "            print('error closing file. continuing...')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Make sure stuff is saving correctly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([5000, 3, 32, 32]),\n",
       " torch.Size([5000]),\n",
       " torch.Size([5000, 3, 32, 32]))"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "samples, labels, interps = torch.load(f'data/{dataset}/{dir_name}/test5000.pt')\n",
    "# assert len(samples.size()) == 4 and len(labels.size()) == 1 and len(interps.size()) == 4\n",
    "samples.shape, labels.shape, interps.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(-0.1228, device='cpu'), tensor(0.1578, device='cpu'))"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "interps[0].min(), interps[0].max()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
